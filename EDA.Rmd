---
title: "EDA"
author: "Team_1"
date: "5/29/2020"
output: html_document 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Package Mang, echo=FALSE}
# Install/Import Packages
install.packages("naniar")

library(naniar)
library(ggplot2)
library(corrplot)
library(dplyr)
library(caret)
library(funModeling)
library(tidyverse) 
library(Hmisc)

```

```{r Import, echo=FALSE}
# Import Data Sets
moddata = read.csv("modelingData.csv", header = TRUE)
projdata = read.csv("projectionData.csv", header = TRUE)
```

Data Cleaning and Wrangling

```{r Data Wrangling, echo=FALSE}
# Data Cleaning / Wrangling (any renaming of variables or standardizing of values.)

```

Exploratory Data Analysis

```{r Outlier, echo=FALSE}
# Outlier Identification and Handling

```

```{r Miss Value, echo=FALSE}
# Missing value identification, summary and possible imputation (mean, median, regression.) This may also be considered part of “Data Wrangling”.

#Create plots to analyize missing data
gg_miss_var(moddata)
vis_miss(moddata, warn_large_data = FALSE)
gg_miss_var(projdata)
vis_miss(projdata, warn_large_data = FALSE)
```

```{r}

############################################
#Address missing values in each column
############################################
#missing values
# create new dataset without missing data
newdata <- na.omit(moddata)


```

```{r}

############################################
#basic plots to analyize data
############################################


# Plot to show the count by Product_type (Investment vs OwnerOccupie)
prodCount <- moddata %>%
  group_by(product_type) %>%
  summarise(counts = n())

ggplot(prodCount, aes(x = product_type, y = counts)) +
  geom_bar(fill = "#0073C2FF", stat = "identity") +
  geom_text(aes(label = counts), vjust = -0.3) + 
  theme_grey()

#PLot Price_doc vs full_sq
ggplot(aes(x=full_sq, y=price_doc), data=moddata) + 
    geom_point(color='blue')

# price_doc is right skwed we can 
ggplot(moddata,aes(x=price_doc))+geom_density(fill="blue",alpha=0.6)
moddata['log_price_doc'] = log(moddata$price_doc)
ggplot(moddata,aes(x=log_price_doc))+geom_density(fill="blue",alpha=0.6)

# % of missed data by features
miss_pct <- map_dbl(moddata, function(x) { round((sum(is.na(x)) / length(x)) * 100, 1) })
miss_pct <- miss_pct[miss_pct > 0]
data.frame(miss=miss_pct, var=names(miss_pct), row.names=NULL) %>%
    ggplot(aes(x=reorder(var, -miss), y=miss)) + 
    geom_bar(stat='identity', fill='blue') +
    labs(x='', y='% missing', title='Percent missing data by feature') +
    theme(axis.text.x=element_text(angle=90, hjust=1))

# Histogram showing build year distribution
moddata %>% 
    filter(build_year > 1940 & build_year < 2018) %>%
    ggplot(aes(x=build_year)) + 
    geom_histogram(fill='blue') + 
    ggtitle('Distribution of build year')

table(moddata$build_year)


str(moddata) 

```

```{r Multicollinearity, echo=FALSE}
# Multicollinearity (is there reason to believe it is present?)  You don’t have to address every potential pair of variables that may be collinear.  Just provide a plot and or other evidence of a single occurrence of multicollinearity if at least one exists and then mention possible other occurrences.  

#Return numeric values only
df_numeric <- moddata[, sapply(moddata, is.numeric)]

#Correlation Plot
df_numeric[is.na(df_numeric)] <- "0"
df_numeric <- df_numeric[, sapply(df_numeric, is.numeric)]
df_corr <- round(cor(df_numeric),2)

corrplot(cor(df_corr), diag = FALSE, order = "FPC",
         tl.pos = "td", tl.cex = 0.5, method = "color", type = "upper")

```

```{r Assumptions, echo=FALSE}
# Homoscedasticity, normal distributions of the response for fixed values of the explanatory variable(s), linear relationship between the mean of the response and each explanatory variable, etc.  This is where you would apply transformations (log, square root, etc.)

```

```{r Variable Selection, echo=FALSE}
# Variable selection: For example, there are many potential explanatory variables. Running stepwise variable selection will not necessarily provide a final model, but may leave you with a smaller set of potential explanatory variables to work with.

```

```{r Miscellaneous, echo=FALSE}
# Anything else that might be appropriate in learning about the data before getting started.  (Example: You might analyze interactions between explanatory variables in the analysis.)

```

```{r LM of independent variables, echo=FALSE}
Indepadj<-lm(formula = logprice~full_sq+life_sq+floor+raion_popul+green_zone_part+indust_part+children_preschool+preschool_quota+children_school+hospital_beds_raion+
               metro_min_avto+metro_km_avto+metro_min_walk+metro_km_walk+school_km+park_km+green_zone_km+industrial_km+railroad_station_walk_km, data = newmodeling
               )
Residuals:
     Min       1Q   Median       3Q      Max 
-0.72226 -0.04661  0.00000  0.07110  0.63828 

Coefficients: (1 not defined because of singularities)
                           Estimate Std. Error t value Pr(>|t|)  
(Intercept)               3.170e+01  9.953e+01   0.319   0.7538  
full_sq                   6.517e-03  3.499e-03   1.863   0.0789 .
life_sq                  -4.156e-03  2.998e-03  -1.386   0.1825  
floor                     9.257e-03  1.205e-02   0.768   0.4524  
raion_popul              -7.596e-04  4.453e-03  -0.171   0.8664  
green_zone_part           5.420e+00  6.126e+01   0.088   0.9305  
indust_part              -4.853e+01  3.284e+02  -0.148   0.8842  
children_preschool        1.760e-02  1.042e-01   0.169   0.8678  
preschool_quota          -5.385e-03  3.201e-02  -0.168   0.8683  
children_school          -3.873e-03  2.317e-02  -0.167   0.8691  
hospital_beds_raion      -1.219e-03  8.434e-03  -0.144   0.8867  
metro_min_avto            3.983e-01  2.888e+00   0.138   0.8918  
metro_km_avto             3.371e-01  5.491e+00   0.061   0.9517  
metro_min_walk           -2.788e-02  4.202e-02  -0.663   0.5155  
metro_km_walk                    NA         NA      NA       NA  
school_km                -1.387e-01  4.980e+00  -0.028   0.9781  
park_km                  -2.985e-01  7.404e-01  -0.403   0.6916  
green_zone_km             1.112e+00  2.778e+00   0.400   0.6935  
industrial_km             1.376e+00  3.996e+00   0.344   0.7346  
railroad_station_walk_km -7.090e-01  2.066e+00  -0.343   0.7354  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.327 on 18 degrees of freedom
Multiple R-squared:  0.7698,	Adjusted R-squared:  0.5395 
F-statistic: 3.343 on 18 and 18 DF,  p-value: 0.007043

```











